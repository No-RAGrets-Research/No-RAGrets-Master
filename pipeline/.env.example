# Dgraph Configuration
DGRAPH_ALPHA_URL=localhost:8080

# LLM Provider Selection
# Options: "openai" or "ollama"
LLM_PROVIDER=openai

# OpenAI Configuration (when LLM_PROVIDER=openai)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4o-mini

# Ollama Configuration (when LLM_PROVIDER=ollama)
# Install Ollama from: https://ollama.ai
# Then run: ollama pull llama3.1:8b
OLLAMA_MODEL=llama3.1:8b
OLLAMA_BASE_URL=http://localhost:11434/v1

# Vision Model Configuration (for figure analysis)
# Options: "openai", "ollama_vision", or "qwen"
VISION_PROVIDER=qwen

# Choose based on VISION_PROVIDER:
# - For openai: VISION_MODEL=gpt-4o (uses OPENAI_API_KEY, ~$0.03-0.10 per paper)
# - For qwen: VISION_MODEL=qwen3-vl:4b (free, local via Ollama)
# - For ollama_vision: VISION_MODEL=llava (free, local via Ollama)
VISION_MODEL=qwen3-vl:4b
VISION_BASE_URL=http://localhost:11434/v1

# Development Tips:
# Text Models (LLM_PROVIDER):
# - Use Ollama for free local development/debugging
# - Switch to OpenAI for production-quality reviews
# - Recommended Ollama models for development:
#   - llama3.1:8b (well-rounded, 4.7GB)
#   - mistral:7b (very fast, 4.1GB)
#   - qwen2.5:7b (fastest feedback, 4.7GB)
#
# Vision Models (VISION_PROVIDER):
# - Use openai/gpt-4o for best figure analysis quality
# - Use ollama_vision/llava for free local testing
# - Hybrid: Ollama for text + GPT-4o for figures = cost-effective
